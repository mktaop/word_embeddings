{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb51e3a2",
   "metadata": {},
   "source": [
    "# Import the following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360587a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pandas as pd, re, numpy as np, string, nltk, tqdm, functools, scipy, time\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from functools import reduce\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "import utils, torch_model_base, torch_autoencoder\n",
    "from torch_autoencoder import TorchAutoencoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f384bbd",
   "metadata": {},
   "source": [
    "# Import your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4b81d",
   "metadata": {},
   "source": [
    "## In case you want to take a random sample of the above file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e442ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mini = data.sample(frac=.01, replace=True, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c329135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.comment=df.comment.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97549ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment']=df['comment'].apply(lambda x: re.sub(r'[^a-zA-Z]+',' ',str(x)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stopwords=[\"xxxx\",\"xxxxxxxx\",\"xx\",\"xxxx.\",\"xxxxxxxx.\",\"xx.\"]\n",
    "df.comment=df['comment'].apply(lambda x:' '.join(\n",
    "    [word for word in x.split() if word not in (new_stopwords)]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11795a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.comment = df['comment'].str.replace('xxxx', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3715e06",
   "metadata": {},
   "source": [
    "# Create co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c225c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=df.comment.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=None, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "X = vect.fit_transform(df_list)\n",
    "uniq_wrds = vect.get_feature_names_out()\n",
    "uniq_wrds = uniq_wrds.tolist()\n",
    "n = len(uniq_wrds)\n",
    "co_mat = np.zeros((n,n))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caaa8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 10\n",
    "\n",
    "def update_co_mat(x):   \n",
    "    # Get all the words in the sentence and store it in an array wrd_lst\n",
    "    wrd_list = x.split(' ')\n",
    "    wrd_list = [ele for ele in wrd_list if ele.strip()]\n",
    "\n",
    "    \n",
    "    # Consider each word as a focus or center word\n",
    "    for focus_wrd_indx, focus_wrd in enumerate(wrd_list):\n",
    "        focus_wrd = focus_wrd.lower()\n",
    "        # Get the indices of all the context words, based on the window size, for the given focus word\n",
    "        for contxt_wrd_indx in range((max(0,focus_wrd_indx - window_len)),(min(len(wrd_list),focus_wrd_indx + window_len +1))):                        \n",
    "            # If context words are in the unique words list\n",
    "            if wrd_list[contxt_wrd_indx] in uniq_wrds:\n",
    "                \n",
    "                # To identify the row number, get the index of the focus_wrd in the uniq_wrds list\n",
    "                co_mat_row_indx = uniq_wrds.index(focus_wrd)\n",
    "                \n",
    "                # To identify the column number, get the index of the context words in the uniq_wrds list\n",
    "                co_mat_col_indx = uniq_wrds.index(wrd_list[contxt_wrd_indx])\n",
    "                \n",
    "                # To calculate the scaled value\n",
    "                if abs(focus_wrd_indx-contxt_wrd_indx)==0:\n",
    "                    scale=1\n",
    "                else:\n",
    "                    #scale=(window_len-abs(focus_wrd_indx-contxt_wrd_indx)+1)/window_len\n",
    "                    scale=1\n",
    "                                \n",
    "                # Update the respective columns of the corresponding focus word row\n",
    "                co_mat[co_mat_row_indx][co_mat_col_indx] += scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in tqdm(df_list):\n",
    "    update_co_mat(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d086d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(co_mat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm=pd.DataFrame(co_mat, columns=uniq_wrds, index=uniq_wrds)\n",
    "df_cm.to_csv('save to your location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495cdac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399da540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe of unique words\n",
    "df_uniq_wrds=pd.DataFrame(uniq_wrds,columns=['word'])\n",
    "df_uniq_wrds.to_csv('save to your location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230278d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniq_wrds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2245a7",
   "metadata": {},
   "source": [
    "# Find the most closest related words to any word in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7db20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbors using cosine or euclidean distance\n",
    "def euclidean(w1, w2):\n",
    "    return scipy.spatial.distance.euclidean(w1, w2)\n",
    "\n",
    "def cosine(w1, w2):\n",
    "    return scipy.spatial.distance.cosine(w1, w2)\n",
    "\n",
    "def neighbors(word, df, distfunc=cosine):\n",
    "\n",
    "    if word not in df.index:\n",
    "        raise ValueError('{} is not in this Vector Space'.format(word))\n",
    "    w = df.loc[word]\n",
    "    dists = df.apply(lambda x: distfunc(w, x), axis=1)\n",
    "    return dists.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neighbors('credit', df_cm, distfunc=cosine).iloc[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57205078",
   "metadata": {},
   "source": [
    "# Re-weight the co-occurrence matrix using PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Calcualte positive PMI ...\n",
    "def observed_over_expected(df):\n",
    "    col_totals = df.sum(axis=0)\n",
    "    total = col_totals.sum()\n",
    "    row_totals = df.sum(axis=1)\n",
    "    expected = np.outer(row_totals, col_totals) / total\n",
    "    oe = df / expected\n",
    "    return oe\n",
    "\n",
    "def pmi(df, positive=True):\n",
    "    df = observed_over_expected(df)\n",
    "    with np.errstate(divide='ignore'):\n",
    "        df = np.log(df)\n",
    "    df[np.isinf(df)] = 0.0  \n",
    "    if positive:\n",
    "        df[df < 0] = 0.0\n",
    "    return df\n",
    "\n",
    "wghtd_df=pmi(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad712c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wghtd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d70bce",
   "metadata": {},
   "source": [
    "Find the most closest related words to any word in the vocabulary in the reweighted matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e3ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neighbors('credit', wghtd_df, distfunc=cosine).iloc[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3dd2a3",
   "metadata": {},
   "source": [
    "# Use LSA to reduce dimensonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce dimensionality using LSA (Latent Semantic Analysis)\n",
    "M_dense=df_cm.to_numpy()\n",
    "M=csr_matrix(M_dense)\n",
    "lsa = TruncatedSVD(n_components=500, n_iter=50, random_state=42)\n",
    "M_lsa=lsa.fit_transform(M)\n",
    "df_lsa=pd.DataFrame(M_lsa, index=uniq_wrds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553eb8a5",
   "metadata": {},
   "source": [
    "Find the most closest related words to any word in the vocabulary in the LSA matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe26610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neighbors('credit', df_lsa, distfunc=cosine).iloc[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71caaf65",
   "metadata": {},
   "source": [
    "# Find the most closest related words to any word in the vocabulary using all 3 matrices we have created so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lookup = 'mortgage'\n",
    "print(f'Top 7 Neighbors using Co-occurrence matrix: \\n----------------------\\n')\n",
    "print(neighbors(word_lookup, df_cm, distfunc=cosine).iloc[1:8])\n",
    "\n",
    "print(f'Top 7 Neighbors using Weighted Co-occurrence matrix: \\n----------------------\\n')\n",
    "print(neighbors(word_lookup, wghtd_df, distfunc=cosine).iloc[1:8])\n",
    "\n",
    "print(f'Top 7 Neighbors using LSA or reduced dimensionality of Co-occurence matrix: \\n----------------------\\n')\n",
    "print(neighbors(word_lookup, df_lsa, distfunc=cosine).iloc[1:8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa78cf6",
   "metadata": {},
   "source": [
    "# Use Autoencoders to further reduce dimensonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31dcdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce dimensionality of co-occurence matris using LSA and Autoencoders\n",
    "df_lsa_ae = TorchAutoencoder(max_iter=1000, hidden_dim=300, eta=0.01).fit(df_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4849f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lsa_ae.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678dac33",
   "metadata": {},
   "source": [
    "Find the most closest related words to any word in the vocabulary in the LSA matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neighbors('credit', df_lsa_ae, distfunc=cosine).iloc[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e858f",
   "metadata": {},
   "source": [
    "Find the most closest related words to any word in the vocabulary using all 4 matrices we have created so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_word='home'\n",
    "\n",
    "print(f'Top 5 Neighbors using Co-occurrence matrix: \\n----------------------\\n')\n",
    "print(neighbors(lookup_word, df_cm, distfunc=cosine).iloc[1:6])\n",
    "\n",
    "print(f'Top 5 Neighbors using Weighted Co-occurrence matrix: \\n----------------------\\n')\n",
    "print(neighbors(lookup_word, wghtd_df, distfunc=cosine).iloc[1:6])\n",
    "\n",
    "print(f'Top 5 Neighbors using LSA or reduced dimensionality of Co-occurence matrix: \\n----------------------\\n')\n",
    "print(neighbors(lookup_word, df_lsa, distfunc=cosine).iloc[1:6])\n",
    "\n",
    "print(f'Top 5 Neighbors using LSA+Autoencoders or reduced dimensionality of Co-occurence matrix: \\n----------------------\\n')\n",
    "print(neighbors(lookup_word, df_lsa_ae, distfunc=cosine).iloc[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66c6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e21f8c2",
   "metadata": {},
   "source": [
    "# Snippet that takes two words and gives you the cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2dbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "a='bank'\n",
    "b='loan'\n",
    "\n",
    "w_a=df_lsa_ae.loc[a]\n",
    "w_b=df_lsa_ae.loc[b]\n",
    "\n",
    "dist_ab=cosine(w_a, w_b)\n",
    "print(\"The distance between '{}' and '{}' is: {}\".format(a, b, dist_ab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df15cb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae3e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43381df4",
   "metadata": {},
   "source": [
    "# Snippet that takes a word and finds the most related word from the final matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaadcf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2nd_closest(input_array, embeddings_df):\n",
    "    input_array = np.array(input_array).reshape(1, -1)\n",
    "    word_embeddings = np.array(embeddings_df.values)\n",
    "    similarities = cosine_similarity(input_array, word_embeddings)\n",
    "    closest_index = np.argsort(similarities[0])[-2] \n",
    "    return closest_index\n",
    "\n",
    "input_word = 'fees'\n",
    "input_emb = df_lsa_ae.loc[input_word]\n",
    "\n",
    "closest_index = find_2nd_closest(input_emb, df_lsa_ae)\n",
    "closest_word=df_lsa_ae.index[closest_index]\n",
    "\n",
    "print(\"The nearest neighbor for '{}' is: {}\".format(input_word, closest_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf6e3f",
   "metadata": {},
   "source": [
    "# Combine any two word vectors to see what will be the nearest word of the combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2nd_closest3(input_array, embeddings_df):\n",
    "    input_array = np.array(input_array).reshape(1, -1)\n",
    "    word_embeddings = np.array(embeddings_df.values)\n",
    "    similarities = cosine_similarity(input_array, word_embeddings)\n",
    "    closest_index = np.argsort(similarities[0])[-1] \n",
    "    return closest_index\n",
    "\n",
    "a1='checking'\n",
    "arr1=df_lsa_ae.loc[a1]\n",
    "a2='fees'\n",
    "arr2=df_lsa_ae.loc[a2]\n",
    "w_comb=(np.multiply(arr1, arr2))/2\n",
    "\n",
    "closest_index = find_2nd_closest3(w_comb, df_lsa_ae)\n",
    "closest_word=df_lsa_ae.index[closest_index]\n",
    "\n",
    "print(\"If you combine '{}' and '{}' then you get: '{}'\".format(a1, a2, closest_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48815a3e",
   "metadata": {},
   "source": [
    "# Create embeddings using LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f658e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflen=len(df)\n",
    "num_comments = dflen\n",
    "max_features = num_comments \n",
    "embedding_dim = 300  #controls the dimensionality\n",
    "window_size = 7 # controls the window size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de283a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df['comment'].tolist()\n",
    "texts = comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb19606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba194b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "context = []\n",
    "target = []\n",
    "for sequence in sequences:\n",
    "    for i in range(window_size, len(sequence) - window_size):\n",
    "        context.append(sequence[i-window_size:i] + sequence[i+1:i+window_size+1])\n",
    "        target.append(sequence[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pad_sequences(context, maxlen=window_size*2)\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33583401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim, input_length=window_size*2))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dense(max_features, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4070b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21434180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(context, target, epochs=15, batch_size=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_embeddings = model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "lstm_embeddings_df = pd.DataFrame(columns=['word'] + [f'embedding_{i+1}' for i in range(embedding_dim)])\n",
    "for i in tqdm(range(1, max_features)):\n",
    "    word = reverse_word_index[i]\n",
    "    embedding = lstm_embeddings[i]\n",
    "    row = pd.Series([word] + list(embedding), index=lstm_embeddings_df.columns)\n",
    "    lstm_embeddings_df = lstm_embeddings_df.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d24d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "lstm_embeddings_df.to_csv('/Users/avi_patel/Documents/yt_project_3K_lstm_embeddings.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_embeddings_df2=lstm_embeddings_df.set_index(list(lstm_embeddings_df)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73398faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_embeddings_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5307ec3",
   "metadata": {},
   "source": [
    "# # Find the most closest related words to any word in the vocabulary using all  the techniques, including LSTM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc656c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_word='credit'\n",
    "\n",
    "print(f'Top 5 Neighbors using Co-occurrence matrix: \\n----------------------\\n')\n",
    "print(neighbors(lookup_word, df_cm, distfunc=cosine).iloc[1:6])\n",
    "\n",
    "print(f'Top 5 Neighbors using Weighted Co-occurrence matrix: \\n----------------------\\n')\n",
    "print(neighbors(lookup_word, wghtd_df, distfunc=cosine).iloc[1:6])\n",
    "\n",
    "print(f'Top 5 Neighbors using LSA or reduced dimensionality of Co-occurence matrix: \\n----------------------\\n')\n",
    "print(neighbors(lookup_word, df_lsa, distfunc=cosine).iloc[1:6])\n",
    "\n",
    "print(f'Top 5 Neighbors using LSA+Autoencoders or reduced dimensionality of Co-occurence matrix: \\n----------------------\\n')\n",
    "print(neighbors(lookup_word, df_lsa_ae, distfunc=cosine).iloc[1:6])\n",
    "\n",
    "print(f'Top 5 Neighbors using LSTM embeddings: \\n----------------------\\n')\n",
    "print(neighbors(lookup_word, lstm_embeddings_df2, distfunc=cosine).iloc[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2nd_closest3(input_array, embeddings_df):\n",
    "    input_array = np.array(input_array).reshape(1, -1)\n",
    "    word_embeddings = np.array(embeddings_df.values)\n",
    "    similarities = cosine_similarity(input_array, word_embeddings)\n",
    "    closest_index = np.argsort(similarities[0])[-1] \n",
    "    return closest_index\n",
    "\n",
    "a1='payment' #is late\n",
    "arr1=lstm_embeddings_df2.loc[a1]\n",
    "z1=arr1.array\n",
    "a2='never' #fees fees\n",
    "arr2=lstm_embeddings_df2.loc[a2]\n",
    "z2=arr2.array\n",
    "a3='posted' #charged penalty\n",
    "arr3=lstm_embeddings_df2.loc[a3]\n",
    "z3=arr3.array\n",
    "dott=np.multiply.reduce((z1, z2, z3))\n",
    "\n",
    "closest_index = find_2nd_closest3(dott, lstm_embeddings_df2)\n",
    "closest_word=lstm_embeddings_df2.index[closest_index]\n",
    "\n",
    "print(closest_word)\n",
    "print(\"If you combine '{}' and '{}' and '{}' then you get: '{}'\".format(a1, a2, a3, closest_word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
